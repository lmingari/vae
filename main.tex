\documentclass[acp, manuscript]{copernicus}
\usepackage{xspace}
\usepackage{bm}

\newcommand*{\eg}{e.g.\@\xspace}
\newcommand*{\ie}{i.e.\@\xspace}
\graphicspath{{figs/}}

\begin{document}

\title{A generative AI model for volcanic ash dispersion}

\Author[1][lmingari@csic.es]{Leonardo}{Mingari} %% correspondence author
\Author[1]{Arnau}{Folch}
\Author[1]{Heribert}{Pascual}
\Author[2]{Manuel}{Titos}

\affil[1]{Geosciences Barcelona (GEO3BCN-CSIC), Barcelona, Spain}
\affil[2]{University of Granada, Granada, Spain}

\runningtitle{AI model for volcanic ash dispersion}

\runningauthor{L. Mingari}

\received{}
\pubdiscuss{} %% only important for two-stage journals
\revised{}
\accepted{}
\published{}

\firstpage{1}

\maketitle

\begin{abstract}
TEXT
\end{abstract}

\introduction 
TEXT

Most of geophysical models are computationally demanding, making the simulation of large ensembles prohibitively expensive, especially in the context of operational services. In order to accommodate the available computing resources, the ensemble is usually limited to a few dozen of simulations, introducing important sampling errors. Generative AI models can generate large ensembles with thousands of samples almost instantaneously at very low computational cost. To this purpose, the AI models must be trained to generate results in agreement with the underlying physical laws governing the atmospheric dispersion and transport of volcanic ash. The Variarional Autoencoder \citet[VAE][]{kingma2013} represent one of the most prominent example of generative model. It consists of an encoder and decoder, like a traditional autoencoder, ...


By perturbing eruption source parameters or meteorological fields, it's possible to run an ensemble of simulation in a very efficient way using FALL3D \citep{folch2022}. However, real-time forecasting using ensembles requires running computationally intensive tasks, which can be challenging even for High-Performance Computing (HPC) clusters. Consequently, the size of the ensemble is usually constrained by the computational resources available. In practice, the number of simulations in the ensemble using Eulerian models is usually limited to a few hundred or even less.

Ensemble modelling allows one to characterise and quantify model uncertainties due to poorly constrained input parameters and errors in the model physics parameterisations or the underlying model-driving meteorological data. In addition, the ability to generate ensemble runs makes it possible to improve forecasts by incorporating observations using different ensemble-based data assimilation techniques.

\citet{chen2025} trained a VAE using sea ice reanalysis and conducted assimilation experiments by means of a particle filter technique. The Latent Space Particle Filter (LSPF) approach takes advantage of a variational autoencoder to extract low-dimensional representations of sea ice physical fields, enabling a large number of low-dimensional samples to be generateda In this way, they significantly reduces model errors by assimilating satellite observations of sea ice concentration and thickness.



%% Copied
%% Several studies have utilized the latent space of VAE for data assimilation, demonstrating its effectiveness in both mathematical theory and practical applications.

\section{Physical model and datasets}
A physical model is used to generate the datasets required for training and evaluation of the variational autoencoder. Specifically, a volcanic ash transport and dispersion (VATD) model was used to simulate the atmospheric transport of ash from a volcanic source. The ensembles of numerical simulations were performed using the latest version release of FALL3D (v9.1), an open source code. FALL3D is an Eulerian model for atmospheric passive transport and deposition of different atmospheric species (\ie, volcanic ash and gases, mineral dust, and radionuclides) and is based on the so-called Advection-Diffusion-Sedimentation (ADS) equation \citep{folch2020,prata2021}. The numerical model is GPU-accelerated using the OpenACC parallel programming model and has been designed to support increasingly larger scientific workloads in preparation for the transition to extreme-scale computing systems \citep{folch2023b}. It has been optimised for the main pre-exascale supercomputer in Europe: LUMI (Finland), Leonardo (Italy) and MareNostrum 5 (Spain).

Ensemble modelling allows one to characterise and quantify model uncertainties due to poorly constrained input parameters and errors in the model physics parameterisations or the underlying model-driving meteorological data. In addition, the ability to generate ensemble runs makes it possible to improve forecasts by incorporating observations using different ensemble-based data assimilation techniques. FALL3D can be run ensembles of simulation in a efficient way through a single parallel task \citep{folch2022}. However, executing a large ensemble of numerical simulations is a high-demanding computational task, even for HPC clusters, and the resources requirement often exceeds the operational capacity of forecasting centres.

\subsection{Ensemble of numerical simulations}
The EU-MODEX Tenerife 2025, organised under the European Civil Protection Mechanism, represented the first large-scale eruption drill in Spain to practice the response to a potential volcanic eruption in Tenerife (Canary Islands) and test evacuation, social assistance and communication during a volcanic crisis. On 26 September 2025, we provided real-time ash-dispersion forecasts to support emergency decision-making using the FALL3D model. These forecasts will be used in this work. The configuration of the FALL3D model is summarised in Table~\ref{tab:model}. We've performed a 24-h forecast assuming continuous emission starting at 09:00UTC. A three-dimensional computational domain with a horizontal resolution of 0.1\degree and $120 \times 100 \times 25$ grid points was defined. The dispersal model was driven by the Global Forecast System (GFS) weather forecast from the National Centers for Environmental Prediction (NCEP).

\begin{table}[t]
    \caption{FALL3D model configuration.}
    \label{tab:model}
    \begin{tabular}{lc}
    \tophline
    Parameter & Value \\ \middlehline
    Start time & 26 September 09:00UTC \\
    Run time & 24~h \\
    Resolution & 0.1\degree $\times$ 0.1\degree \\
    Number of grid points & 120$\times$100$\times$25 \\
    Species & 3 tephra bins \\
    Grain Size Distribution  & bi-Gaussian \\
    Emission source & Suzuki source \citep{pfeiffer2005} \\
    Mass emission rate & Estimated from column height~\citep{woodhouse2016} \\
    Ensemble size & 64,256 and 2048 \\
    \bottomhline
    \end{tabular}
\end{table}

The ensembles were generated by perturbing the Eruption Source Parameters (ESP) and the horizontal wind components using the Latin Hypercube Sampling \citep[LHS,][]{mckay1979} to efficiently sample the parameter space. Table~\ref{tab:ensemble} lists the reference value and sampling uncertainty range for each perturbed parameter. A constant eruptive column top height was assumed for each ensemble member sampled around the central value $H=9~\text{km avl}$ (above vent level). In addition, the wind components were perturbed assuming a sampling range of $25\%$. The eruptive column height and the wind are widely reconsigned as the most sensitive parameters for volcanic ash transport models (add REF).

\begin{table}[t]
  \caption{Ensemble configuration. The perturbed model parameters are: eruption column height ($H$), mass eruptive rate ($MER$), Suzuki parameter $A_s$ and the wind horizontal components.}
    \label{tab:ensemble}
    \begin{tabular}{lccc}
    \tophline
    Parameter        & Reference value        & Distribution & Sampling range  \\ \middlehline
    $H$              & 15~km avl$^\dag$       & Uniform      & $\pm$30\%       \\
    $MER$            & $\sim$1.6E6~kg/s$^\ddag$ & Uniform      & $\pm$25\%       \\
    $A_s$            & 4                      & Uniform      & 1               \\
    U wind           & GFS$^\S$               & Uniform      & $\pm$25\%       \\
    V wind           & GFS$^\S$               & Uniform      & $\pm$25\%       \\ \bottomhline
    \end{tabular}
    \belowtable{%
        $^\dag$ Height given in km above the vent level; \\
        $^\ddag$ Estimated from $H$ according to~\citet{woodhouse2016}; \\
        $^\S$ Global Forecast System (GFS) weather forecast from NCEP.
    }
\end{table}

A total of three numerical simulations were conducted in order to generate a training dataset (simulation A), a validation dataset (simulation B) and test dataset (simulation C). As summarized in Table~\ref{tab:runs}, simulation A produces an ensemble with 256 members, which is used to train the VAE. The ensemble consisting of 64 members generated by simulation B is used during training to monitor performance and tuning hyperparameters. The 2048-member ensemble is used at the end to evaluate the final model and provides a fair (unbiased) report of model performance.

\begin{table}[]
  \caption{Dataset built from ensemble of numerical simulations.}
  \label{tab:runs}
\begin{tabular}{lll}
  \tophline
  Simulation & Ensemble size & Dataset    \\ \middlehline
  A          & 256           & Training   \\
  B          & 64            & Validation \\
  C          & 2048          & Test       \\ \bottomhline
\end{tabular}
\end{table}

\section{Variational Autoencoder}
A Variational Autoencoder (VAE) is a type of generative machine learning model based on a neural network architecture capable of learning an efficient, probabilistic encoding of data into a latent space of low dimensionality~\citep{kingma2013}. By sampling vectors $\vec{z}$ from the learned distribution, a decoder can generate new and realistic data samples, even when the network was trained to encode complex and high-dimensional input data. The scheme in Fig.~\ref{fig:vae} shows a typical architecture of a VAE composed of convolutional layers. The encoder maps inputs $\vec{x}$ to the parameters of a probability distribution (\eg, a Gaussian with parameters $\vec{\mu}$ and $\vec{\sigma}$) over the latent space, from which a latent vector $\bm{z}$ is sampled. This vector is passed to the decoder, which aims to reconstruct the original input. 

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{f01}
  \caption{The basic scheme of a variational autoencoder composed of
  two-dimensional convolutional layers. The encoder compresses an input
  $\vec{x}$ into the low-dimensional latent space. The decoder attempts
  to reconstruct the original data from a vector $\vec{z}$ sampled from the
  latent space. }
  \label{fig:vae}
\end{figure}

The VAE training is guided by a loss function balancing the fidelity of the data reconstruction against a term that regularizes the latent distributions toward a simple prior $p(\vec{z})$:

\begin{equation}
  \mathcal{L}_{VAE}(\theta,\phi;\vec{x}) = -\mathbb{E}_{q_{\phi}(\vec{z}\vert\vec{x})}
  \left[ \log p_{\theta}(\vec{x} \vert \vec{z}) \right] + 
  D_{KL} \left( q_{\phi}(\vec{z}\vert\vec{x}) \Vert p(\vec{z}) \right)
  \label{eq:vae_loss}
\end{equation}
where $q_{\phi}(\vec{z}\vert\vec{x})$ is the encoder approximate posterior and $p_{\theta}(\vec{x} \vert \vec{z})$ the decoder likelihood.

The first term (reconstruction loss) encourages reconstructions to be accurate and, in this work, is assumed to be the mean squared error (MSE) between the input ($\vec{x}$) and its reconstruction (\vec{x}'):
\begin{equation}
  \mathcal{L}_R = \dfrac{1}{N} \sum_{i=1}^N (x_i - x'_i)^2
\end{equation}

The second term in (\ref{eq:vae_loss}) is defined in terms of the Kullback-Leibler (KL) divergence, $D_{KL}$, and measures the difference between the approximate posterior $q_{\phi}(\vec{z} \vert \vec{x})$ and the prior distribution $p(\vec{z})$. In practice, the KL term forces $q_{\phi}$ to be close to the prior $p(\vec{z})$. Traditionally, the standard VAE assumes a diagonal multivariate normal distribution for the approximate posterior, $q_{\phi}(\vec{z} \vert \vec{x}) = \mathcal {N}(\vec{\mu}, \vec{\sigma^2} \mathbb{I} )$, and a standard normal distribution for the prior, $p(\vec{z}) = \mathcal {N}(\vec{0},\mathbb{I})$, leading to:

\begin{equation}
  \mathcal{L}_{KL} = -\dfrac{1}{2} \sum_{i=1}^k \left[1+\log \sigma_i^2 - \mu_i^2 - \sigma_i^2 \right]
\end{equation}
being $\vec{\mu} = (\mu_1,\dots,\mu_k)^{\intercal}$ the vector of means, $\vec{\sigma^2} = (\sigma_1^2,\dots,\sigma_k^2)^{\intercal}$ the vector of variances and $k$ the dimension of $\vec{z}$.

Finally, the $\beta$-VAE is a modification of the standard VAE that uses a hyperparameter, $\beta$, to weight the KL divergence term in the loss function:
\begin{equation}
  \mathcal{L}_{VAE} = \mathcal{L}_R + \beta \, \mathcal{L}_{KL}
\end{equation}
This is the expression of the loss function used in this work.

\subsection{Training}
A Variational Autoencoder (VAE) was implemented in the PyTorch framework~\citep{paszke2019} using an architecture based on two-dimensional convolutional layers. The VAE configuration is defined by list of hyperparameters reported in Table~\ref{tab:hyperparameters}. The neural network was trained in batches using the Adam optimizer for 400 epochs. The reconstruction loss and KL divergence (averaged over the batches) are reported for each epoch in Fig.~\ref{fig:loss} for both the training and validation datasets in order to prevent overfitting. The training (validation) dataset is composed by a 256(64)-member ensemble of modelled volcanic ash column mass on a two-dimensional grid of size $120 \times 100$. As outlined in the scheme of Fig.~\ref{fig:vae}, the encoder network maps the input data $\vec{x} \in \mathbb{R}^{120\times100}$ through three successive convolutional layers, followed by a flattening operation, to two distinct latent space parameter vectors: $\vec{\mu}$ (mean) and $\vec{\sigma}^2$ (log-variance). The decoder then reconstructs the input $\vec{x'}$ from the sampled latent vector $\vec{z} \in \mathbb{R}^{16}$ using a fully connected layer followed by three transposed convolutional layers (or deconvolutional layers), restoring the spatial dimensions, \ie $\vec{x'} \in \mathbb{R}^{120\times100}$.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{loss}
  \caption{%
    Training history for the variational autoencoder (VAE) through 400 epochs. %
    The reconstruction loss ($\mathcal{L}_R$) and KL divergence ($\mathcal{L}_{KL}$) %
    are shown separately for the training and validation datasets for each epochs. %
    The total loss function is given by $\mathcal{L}_R + \beta \, \mathcal{L}_{KL}$. 
    In this configuration we used a latent dimension of 16 and a $\beta=6$.
    }
  \label{fig:loss}
\end{figure}

Figure~\ref{fig:latent_space}a shows the training and test datasets encoded in latent space (just two arbitrary components of the latent vector are shown, \ie $z_5$ vs $z_4$). As expected by construction, the components of the latent vector are distributed according independent standard normal distributions: $z_i \sim \mathbb{N}(0,1)$. A very low correlation between every pair $(z_i,z_j)$ is confirmed by the correlation matrix (Fig.~\ref{fig:latent_space}b). Notice that the samples from the test dataset are filling the same area as the samples used for training the network. All these remarks as a whole indicate that the network was correctly trained and works as expected.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{latent_space}
  \caption{%
    Latent space representation of the training and test datasets. %
    As an example, the encoding in the latent plane $(z_5,z_4)$ 
    is shown in a scatter plot (a). %
    The independence between the distributions of the latent vector 
    components can be confirmed from the correlation matrix (b). 
    }
  \label{fig:latent_space}
\end{figure}

\begin{table}[t]
  \caption{Hyperparameters used for the VAE training.} \label{tab:hyperparameters}
  \begin{tabular}{lccc}
    \tophline
    Hyperparameter       & Value \\ \middlehline
    Latent dimension     & 16 \\
    $\beta$              & 6 \\
    Data size            & 120$\times$100 \\
    Number of epochs     & 400 \\
    Batch size           & 16 \\ 
    Convolutional layers & 6 \\
    Output channels      & 16, 32 and 64 \\
    Kernel Size          & 3$\times$3 \\
    Stride               & 1$\times$1 \\
    Activation function  & ReLU \\
    Learning rate        & 1E-3 \\
    Optimizer            & Adam \\
    Normalization        & Percentile-based scaling \\
    \bottomhline
  \end{tabular}
\end{table}

\subsection{Evaluation metrics} \label{sec:metrics}
Since the VAE was trained using a physical model, in the best case scenario, the samples generated by the VAE, $\left\{ \vec{x_i} \right\}$, should ideally resemble the distribution of a large ensemble produced by the same physical model, $\left\{ \vec{\hat{x}_i} \right\}$. Consequently, probabilistic distributions or sample statistics, such as the sample mean or sample standard deviation, are compared against the reference ensemble $\left\{ \vec{\hat{x}_i} \right\}$, defined by the test dataset consisting of 2048 simulations. In other words, we train a generative AI model using a 256-member ensemble and the performance is evaluated against a 2048-member ensemble.

A few performance metrics are proposed to quantify the ability of the generative AI model to produce realistic ash concentration outputs. For example, the Root-Mean-Square Error (RMSE)
\begin{equation}
  \text{RMSE} = \sqrt {\frac{1}{p}\sum^p_{j=1} (y_j-\hat{y}_j)^2}
  \label{eq:rmse}
\end{equation}
can be evaluated in terms of the sample means, \ie $\vec{y} = 1/N \sum \vec{x_i}$ and $\vec{\hat{y}} = 1/\hat{N} \sum \vec{\hat{x}_i}$.

The KL divergence is a measure of the difference between two probability distributions. Specifically, for two discrete distributions $P = \{p_i\}$ and $Q=\{q_i\}$, the KL divergence can be interpreted as the expected logarithmic difference between the probability distributions:
\begin{equation}
  D_{KL}(P \Vert Q) = \sum p_i \log \dfrac{p_i}{q_i}
  \label{eq:kl}
\end{equation}
The discrete distributions are computed from the histograms corresponding to each ensemble.

The two-dimensional isotropic power spectrum, $P(k)$, is computed in order to assess the ability of the VAE to generate realistic samples over different spatial scales, in consistency with physical models. It's defined as the radially averaged 2D Power Spectrum Density (PSD) and is a function of the wavenumber magnitude, $k$:
\begin{equation}
  P(k) = \dfrac{1}{N_k} \sum PSD(k_x,k_y)
  \label{eq:psd}
\end{equation}
where $k=\sqrt{k_x^2 + k_y^2}$ is the magnitude of the wavevector, $PSD(k_x,k_y)$ is the two-dimensional Power Spectral Density obtained from a Fast Fourier Transform (FFT), and $N_k$ is the number of data points within a annular ring around $k$ in the Fourier space.

\section{Results and discussion}
Once the VAE neural network has been trained with numerical simulations based on a physical model, it's possible to generate new physics-grounded samples at very low computational cost that are consistent with the underlying physical laws governing atmospheric dispersion. Figure~\ref{fig:vae_ensemble} shows a VAE-generated ensemble consisting of 12 samples. The samples represent two-dimensional ash column mass, \ie the vertically integrated ash mass per unit area. The variability in the ensemble is a consequence of the different eruptive source parameters (\eg, eruptive column height) and meteorological fields used to simulate the training dataset. For examples, samples in Fig.~\ref{fig:vae_ensemble}c,d correspond to cases with high eruptive column heights and strong emission, whereas other samples, such as~Fig.~\ref{fig:vae_ensemble}h, are associated to lower column heights and weak emission.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{vae_ensemble}
  \caption{%
    VAE-generated ensemble composed of 12 samples. %
    The neural network was trained to generate samples %
    of two-dimensional ash column mass, \ie the total %
    mass of volcanic ash in a vertical column.
    }
  \label{fig:vae_ensemble}
\end{figure}

\subsection{Sensitivity study}
We trained multiple VAEs changing the latent space dimension and $\beta$ (see~\ref{eq:vae_loss}), while the remaining hyperparameters remain fixed as specified in Table~\ref{tab:hyperparameters}. The performance was evaluated in term of the ensemble mean RMSE (see~\ref{eq:rmse}). To this purpose, 2048-member ensembles were generated and the RMSE was computed for each ensemble. Since the VAE is a probabilistic model, each sampled ensemble will yield different results. The boxplot in Fig.~\ref{fig:boxplot} reflects this variability considering 20 ensembles generated using the same hyperparameters. In all cases, the network was trained for 400 epochs, except for the configurations with latent dimension of 4 and 2, where early stopping was required to avoid overfitting. According to the trend suggested by Fig.~\ref{fig:boxplot}, the best performance is achieved for latent dimensions above 6 and $\beta\gtrsim 6$. Next, we present results using a latent dimension of 16 and $\beta=6$, as indicated in Table~\ref{tab:hyperparameters}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{boxplot}
  \caption{VAE performance for different hyperparameters in term of the ensemble mean RMSE.}
  \label{fig:boxplot}
\end{figure}

\subsection{Ensemble mean and spread}
The ensemble mean and spread (standard deviation) are shown in Fig.~\ref{fig:mean_spread} for the training dataset (a,d), a 5000-member ensemble generated by the VAE (b,e) and the test dataset (c,f). The statistics computed for the training dataset and the VAE are similar to those computed for the test dataset, although some differences can be identified in Fig.~\ref{fig:mean_spread}e for the VAE ensemble spread.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{mean_spread}
  \caption{Ensemble mean (a,b,c) and ensemble spread (d,e,f) computed from the training dataset (left column), ensemble VAE with 5000 samples (central column) and the test dataset (right column).}
  \label{fig:mean_spread}
\end{figure}

\subsection{Probability distributions}
A proper assessment of natural hazard involves a good estimation of probabilities. For example, it may be desirable to estimate the exceedance probability, \ie the probability that a specific hazard's value will be exceeded within a given timeframe. For this reason, it is essential to have an accurate description of probability distributions based on the ensembles.

In Fig.~\ref{fig:exceedance} exceedance probabilities considering different thresholds (8,14,20~$g~m^{-2}$) are shown. Again, the probability maps reveals that the VAE is able to generate realistic samples with the correct probability distribution.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{exceedance_probability}
  \caption{Exceedance probabilities for three thresholds: 8,14 and 20~$g~m^{-2}$. Left column shows the results for the training dataset, central column corresponds to a VAE ensemble of 5000 samples and the right column shows the results for the test dataset.}
  \label{fig:exceedance}
\end{figure}

To explore this point further, a few histograms for different locations are shown in Fig.~\ref{fig:histograms} comparing results for the training dataset (left column) and a VAE ensemble with 5000 samples (right column). As expected, the distribution for the training dataset with a small ensemble size (256) results in a very noisy distribution, while the VAE distribution provides a good approximation of the test dataset, even for multimodal distributions (\eg, Fig.~\ref{fig:histograms}b).

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{histograms}
  \caption{%
    Histograms for the training datasets (256 samples, left column) and 
    a VAE ensemble (2048 samples, right column) at the different locations.
    The results are compared against the test dataset (5000 samples),
    considered as a reference (yellow shaded area).
    }
  \label{fig:histograms}
\end{figure}

In order to quantify the difference between two probability distributions, the KL divergence~(\ref{eq:kl}) is computed taking as a reference the discrete probability distribution $P^{Test} = \{p_1,\dots,p_{nbins}\}$, corresponding to the test dataset. Basically, we want to examine if the VAE ensemble provides a better approximation to the actual distribution. To this purpose, the VAE KL divergence is computed from $Q^{VAE}$ (\ie, the VAE discrete probability distribution) using:
\begin{equation}
  D^{VAE}_{KL} = D_{KL}(Q^{VAE} \Vert P^{Test})
\end{equation}
The results are shown in Fig.~\ref{fig:kl_divergence}a. Similarly, Fig.~\ref{fig:kl_divergence}b shows the train KL divergence:
\begin{equation}
  D^{Train}_{KL} = D_{KL}(Q^{Train} \Vert P^{Test})
\end{equation}
being $Q^{Train}$ the training dataset distribution. In general, VAE yields lower values ($D^{VAE}_{KL}<D^{Train}_{KL}$), meaning that the VAE provides a better approximation of the actual distribution. However, looking at the differences between the divergences, $D^{VAE}_{KL} - D^{Train}_{KL}$ (Fig.~\ref{fig:kl_divergence}c), it is possible conclude that in some regions the training dataset outperforms the samples generated by the VAE (positive differences, red shaded areas).

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.5\textwidth]{kl_divergence}
  \caption{%
    Kullback Leibler (KL) divergence computed from the VAE ensemble (a) and the training dataset (b). From the difference between both divergences (c) it is possible conclude if the actual probability distribution is better approximated by the VAE ensemble (negative differences) or the training ensemble (positive differences).
    }
  \label{fig:kl_divergence}
\end{figure}

\subsection{Isotropic power spectrum}
The isotropic power spectrum, \ie the radially averaged two-dimensional Power Spectral Density (PSD), was computed for each sample for the ensemble using (\ref{eq:psd}). The ensemble average is presented in Fig.~\ref{fig:psd} for samples generated by the VAE and for the test dataset. In both cases the ensemble size is 2048. Instead of the classical energy cascade spectrum according to $\propto k^{-5/3}$, the dispersal model exhibits an exponential decay as consequence of the diffusion processes modelled by FALL3D (solid black line). The generative model reproduces large scales but fails at scales smaller, as shown in Fig.~\ref{fig:psd} (blue circles). In this case, the isotropic power spectrum deviates from exponential decay for wavenumbers above $0.25~\Delta x^{-1}$, approximately, where $\Delta x$ is the grid size. In other words, the variational autoencoder is unable to reproduce the variability over spatial scales below $\sim 4~\Delta x$.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.5\textwidth]{psd}
  \caption{The isotropic power spectrum, \ie radially averaged two-dimensional Power Spectral Density, reveals inconsistencies in the spatial structure of the samples generated by the variational autoencoder. The generative model reproduces large scales but fails at scales smaller since the AI model is introducing artificial noise for large k. Since the wavenumber is expressed in terms of the grid size, $\Delta x$, we can conclude that the VAE is unable to reproduce the variability over spatial scales below $\sim 4~\Delta x$, approximately. }
  \label{fig:psd}
\end{figure}

\conclusions \label{sec:conclusions}
%
%Short summary
This paper has explored the properties of a generative AI model for volcanic ash transport based on a Variational Autoencoder (VAE), a type of machine learning model capable of learning a probabilistic representation of data in a low dimensional latent space and generate new data, similar to that simulated by a physical model.

\codeavailability{
  FALL3D v9.1 is available under the version 3
  of the GNU General Public License (GPL) at
  \url{https://gitlab.com/fall3d-suite/fall3d/} and 
  \url{https://doi.org/10.5281/zenodo.14198155}
  \citep{folch2020,prata2021}.
  %
}

\authorcontribution{
  Conceptualisation, L.M., M.T.; %
  Methodology, L.M.; %
  Software, L.M., A.F., H.P.; %
  Resources, L.M.; %
  Writing---original draft, L.M.; %
  Writing---review and editing, L.M., A.F., H.P., M.T.; %
  Visualisation, L.M.; %
  Supervision, A.F.; %
  Funding Acquisition, A.F.
  %
  All authors have read and approved the final version of the manuscript.
}

\competinginterests{The authors declare that they have no conflict of interest.} 

\begin{acknowledgements}
  This work has been partially funded by the EuroHPC
  Center of Excellence for Exascale in Solid Earth - 
  Second phase (ChEESE-2P) under the Grant Agreement No. 101093038.
\end{acknowledgements}

%% REFERENCES
\bibliographystyle{copernicus}
\bibliography{references.bib}

\end{document}
